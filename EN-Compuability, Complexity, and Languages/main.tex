\documentclass[12pt,a4paper,twoside,openany]{book}
\usepackage{amd}
\usepackage{booktabs}
\usepackage{mathrsfs}

% %--------------------------------------------------------------------------
% %         General Setting
% %--------------------------------------------------------------------------

\graphicspath{{Images/}{../Images/}} %Path of figures
\setkeys{Gin}{width=0.85\textwidth} %Size of figures
\setlength{\cftbeforechapskip}{3pt} %space between items in toc
\setlength{\parindent}{0.5cm} % Idk
\input{theorems.tex} % Theorems styles and colors
\usepackage[english]{babel} %Language

\setlist[itemize]{itemsep=3pt} % Adjust the length as needed
\setlist[enumerate]{itemsep=3pt} % Adjust the length as needed

\usepackage{lmodern} %  Latin Modern font

% %--------------------------------------------------------------------------
% %         General Informations
% %--------------------------------------------------------------------------
\newcommand{\BigTitle}{
    Computability, Complexity, and Languages
    }

\newcommand{\LittleTitle}{
    By Martin D. Davis et al
    }

    
\begin{document}

% %--------------------------------------------------------------------------
% %         First pages 
% %--------------------------------------------------------------------------
\newgeometry{top=8cm,bottom=.5in,left=2cm,right=2cm}
\subfile{files/0.0.0.titlepage}
\restoregeometry
\thispagestyle{empty}
\setcounter{page}{0}
\tableofcontents
\thispagestyle{empty}
\setcounter{page}{0}

% %--------------------------------------------------------------------------
% %         Core of the document 
% %--------------------------------------------------------------------------

\chapter{Preliminaries}
\section{Sets and $n$-tuples}

We shall often be dealing with \textit{sets} of objects of some definite kind. Thinking of a collection iof entities as a \textit{set} simply amounts to a decision to regard the whole collection as a single object. We shall use the word \textit{class} as synonymous with \textit{set}. In particular we write $N$ for the set of \textit{natural numbers} $0,1,2,3\cdots$.

It is useful to speak of the \textit{empty set}, written $\varnothing$, which has no members. The equation $R=S$, where $R$ and $S$ are sets, means that $R$ and $S$ are \textit{identical as sets}, that is, that they have exactly the same members. We write $R\subseteq S$ and speak of $R$ as a \textit{subset} of $S$ to mean that every element of $R$ is also an element of $S$. We write $R\subset S$ to indicate that $R\subseteq S$ but $R\neq S$. In this case $R$ is called a \textit{proper subset} of $S$. If $R$ and $S$ are set, we write $R\cup S$ for the \textit{union} of $R$ and $S$, which is the collection of all objects which are members of either $R$ or $S$ or both. $R\cap S$, the \textit{intersection} of $R$ and $S$, is the set of all objects that belong to both $R$ and $S$. $R-S$, the set of all objects that belong to $R$ and do not belong to $S$, is the \textit{difference} between $R$ and $S$. Often we will be working in contexts where all sets being considered are subsets of some fixed set $D$ (sometimes called a \textit{domain} or a \textit{universe}). In such a case we write $\bar{S}$ for $D-S$, and call $\bar{S}$ the \textit{complement} of $S$. We write $$\{a_1,a_2,\cdots,a_n\}$$ for the set consisting of the $n$ objects $a_1,a_2,\cdots,a_n$. Sets that can be written in this form as well as the empty set are called \textit{finite}. Sets that are not finite are called \textit{infinite}. Since two sets are equal if and only if they have the same members. That is, the order in which we may choose to write the members of a set is irrelevant. Where order is important, we speak instead of an $n$-tuple or a \textit{list}. A 2-tuple is called an \textit{ordered pair}, and a 3-tuple is called an \textit{ordered triple}. Unlike the case for sets of one object, we \textit{do not distinguish between the object $a$ and the 1-tuple $(a)$}. The crucial property of $n$-tuples is $$(a_1,a_2,\cdots,a_n)=(b_1,b_2,\cdots,b_n)$$ \textit{if and only if} $$a_{1}=b_{1} ,\quad a_{2}=b_{2} ,\quad\ldots,\quad and\quad a_{n}=b_{n}.$$

If $S_1,S_2,\cdots,S_n$ are given sets, then we write $S_1\times S_2\times\cdots\times S_n$ for the set of all $n$-tuples such that $a_1\in S_1,a_2\in S_2,\cdots,a_n\in S_n$. $S_1\times S_2\times\cdots\times S_n$ is sometimes called the \textit{Cartesian product} of $S_1,S_2,\cdots,S_n$.

\section{Functions}

For $f$ a function, one writes $f(a)=b$ to mean that $(a,b)\in f$; the definition of function ensures that for each $a$ there can be at most one such $b$. The set of all $a$ such that $(a,b)\in f$ for some $b$ is called the \textit{domain} of $f$. The set of all $f(a)$ for $a$ in the domain of $f$ is called the \textit{range} of $f$.

Functions $f$ are often specified by \textit{algorithms} that provide procedures for obtaining $f(a)$ from $a$. However, it is quite possible to possess an algorithm that specifies a function without being able to tell which elements belong to its domain. This makes the notion of a so-called \textit{partial function} play a central role in computability theory. A \textit{partial function on a set} $S$ is simply a function whose domain is a subset of $S$. If $f$ is a partial function on $S$ and $a\in S$, then we write $f(a)\downarrow$ and say that $f(a)$ is \textit{defined} to indicate that $a$ is in the domain of $f$; if $a$ is not in the domain of $f$, we write $f(a)\uparrow$ and say that $f(a)$ is \textit{undefined}. If a partial function on $S$ has the domain $S$, then it is called \textit{total}. Finally, we should mention that the empty set $\varnothing$ is itself a function. Considered as a partial function on some set $S$, \textit{it is nowhere defined}.

A partial function $f$ on a set $S^n$ is called an \textit{n-ary partial function on} $S$, or a function of $n$ variables on $S$. We use \textit{unary} and \textit{binary} for 1-ary and 2-ary, respectively.

A function $f$ is \textit{one-one} if, for all $x,y$ in the doamin of $f$, $f(x)=f(y)$ implies $x=y$. If the range of $f$ is the set $S$, then we say that $f$ is an \textit{onto} function with respect to $S$, or simply that $f$ is \textit{onto} $S$.

We will sometimes refer to the idea of \textit{closure}. If $S$ is a set and $f$ is a partial function on $S$, then $S$ is \textit{closed under} $f$ if the range of $f$ is a subset of $S$.

\section{Alphabets and Strings}

An \textit{alphabet} is simply some finite nonempty set $A$ of objects called \textit{symbols}. An $n$-tuple of symbols of $A$ is called a \textit{word} or a \textit{string} on $A$. The set of all words on the alphabet $A$ is written $A^*$. Any subset of $A^*$ is called a \textit{language on} $A$ or a \textit{language with alphabet} $A$. We do \textit{not} distinguish between a symbol $a\in A$ and the word of length 1 consisting of that symbol.

\section{Predicates}

By a \textit{predicate} or a \textit{Boolean-valued function} on a set $S$ we mean a \textit{total} function $P$ on $S$ such that for each $a\in S$, either $$P(a)=\mathrm{TRUE}\quad\mathrm{or}\quad P(a)=\mathrm{FALSE},$$ where TRUE and FALSE are a pair of distinct objects called \textit{truth values}. We often say $P(a)$ \textit{is true} for $P(a)=$TRUE, and $P(a)$ \textit{is false} for $P(a)=$FALSE. Given a predicate $P$ on a set $S$, there is a corresponding subset $R$ of $S$, namely, the set of all elements $a\in S$ for which $P(a)=1$. The predicate $P$ is called the \textit{characteristic function} of the set $R$.

\section{Quantifiers}

In this section we will be concerned exclusively with predicates on $N^m$ (or what is the same thing, $m$-ary predicates on $N$) for different values of $m$. Thus, let $P(t,x_1,\cdots,x_n)$ be an $(n+1)$-ary predicate. Consider the predicate $Q(y,x_1,\cdots,x_n)$ defined by $$\begin{aligned}Q(y,x_{1},\ldots,x_{n})\Leftrightarrow&P(0,x_{1},\ldots,x_{n})\vee P(1,x_{1},\ldots,x_{n})\\ &\vee\cdots\vee P(y,x_{1},\ldots,x_{n}).\end{aligned}$$ Thus the predicate $Q(y,x_1,\cdots,x_n)$ is true just in case there is value of $t\le y$ such that $P(t,x_1,\cdots,x_n)$ is true. We write this predicate $Q$ as $$(\exists t)_{\leq y}P(t,x_{1},\ldots,x_{n}).$$ The expression "$(\exists t)_{\leq y}$" is called a \textit{bounded existential quantifier}. Similarly, we write $(\forall t)_{\le y}P(t,x_1,\ldots,x_n)$ for the predicate $$P(0,x_1,\ldots,x_n)\&P(1,x_1,\ldots,x_n)\&\cdots\&P(y,x_1,\ldots,x_n).$$ The predicate is true just in case $P(t,x_1.\cdots,x_n)$ is true for \textit{all} $t\le y$. The expression "$(\forall t)_{\le y}$" is called a \textit{bounded universal quantifier}.

\section{Proof by Contradiction}

Recall that a number is called a \textit{prime} if it has \textit{exactly two distinct divisors}, itself and 1. Consider the following assertion:
\begin{center}
    $n^2-n+41$ is prime for all $n\in N$.
\end{center}
This assertion is in fact \textit{false}.

In a \textit{proof by contradiction}, one begins by supposing that the assertion we wish to prove is false. In a proof by contradiction we look for a pair of statements developed in the course of the proof which \textit{contradict} one another.

\thm{} {
    Let $x\in\{a,b\}^*$ such that $xa=ax$. Then $x=a^{[n]}$ for some $n\in N$.
}

\section{Mathematical Induction}

Mathematical induction furnishes an important technique for proving statements of the form $(\forall n)P(n)$, where $P$ is a predicate on $N$. One proceeds by proving a pair of auxiliary statements, namely, $P(0)$ and
\begin{equation}
    (\forall n)(\textit{if }P(n)\textit{ then }P(n+1)).
    \label{7.1}
\end{equation}

Why is this helpful? Because sometimes it is much easier to prove (\ref{7.1}) than to prove $(\forall n)P(n)$ in some other way. In proving this second auxiliary proposition one typically considers some fixed but arbitrary value $k$ of $n$ and shows that if we assume $P(k)$ we can prove $P(k+1)$. $P(k)$ is then called the \textit{induction hypothesis}.

There are some paradoxical things about proofs by mathematical induc­tion. One is assuming $P(k)$ for some \textit{particular} $k$ in order to show that $P(k+1)$ follows.

It is also paradoxical that in using induction (we shall often omit the word \textit{mathematical}), it is sometimes easier to prove statements by first making them "stronger." We wish to prove $(\forall n)P(n)$. Instead we decide to prove the \textit{stronger} assertion $(\forall n)(P(n)\&Q(n))$ (which of course implies the original statement). The technique of deliber­ately strengthening what is to be proved for the purpose of making proofs by induction easier is called \textit{induction loading}.

\thm{} {
    For all $n\in N$ we have $\sum_{i = 0}^n(2i + 1)=(n + 1)^2$.
}

Another form of mathematical induction that is often very useful is called \textit{course-of-values induction} or sometimes \textit{complete induction}.

\thm{} {
    There is no string $x\in\{a,b\}^*$ such that $ax=xb$.
}

\chapter{Programs and Computable Functions}
\section{A Programming Language}

In particular, the letters $$X_1\;X_2\;X_3\;\cdots$$ will be called the \textit{input variables} of $\mathscr{L}$, the letter $Y$ will be called the \textit{output variable} of $\mathscr{L}$, and the letters $$Z_1\;Z_2\;Z_3\;\cdots$$ will be called the \textit{local variables} of $\mathscr{L}$.

In $\mathscr{L}$ we will be able to write "instructions" of various sorts; a "program" of $\mathscr{L}$ will then consist of a \textit{list} (i.e., a finite sequence) of instructions.

\begin{table}[htbp]
    \caption{}
    \begin{tabular}{p{0.2\columnwidth}p{0.8\columnwidth}}
        \toprule
        \multicolumn{1}{c}{Insturction} & \multicolumn{1}{c}{Interpretation}                                                                                       \\
        \midrule
        $V\leftarrow V+1$     & Increase by 1 the value of the variable $V$.                                                                                       \\
        $V\leftarrow V-1$     & If the value of $V$ is 0, leave it unchanged; otherwise decrease by 1 the value of $V$.                                            \\
        IF $V\neq 0$ GOTO $L$ & If the value of $V$ is nonzero, perform the instruction with label $L$ next; otherwise proceed to the next instruction in the list \\
        \bottomrule
    \end{tabular}
    \label{table:1.1}
\end{table}

We give in Table \ref{table:1.1} a complete list of our instructions. In this list $V$ stands for any variable and $L$ stands for any label.

These instructions will be called the \textit{increment}, \textit{decrement}, and \textit{conditional branch} instructions, respectively.

We will use the special convention that \textit{the output variable} $Y$ \textit{and the local variables} $Z_i$ \textit{initially have the value} 0.

\section{Some Examples of Programs}

Our first example is the program
\begin{equation*}
    \begin{array}{ll}[A]&\quad X\leftarrow X-1\\ &\quad Y\leftarrow Y+1\\ &\quad\text{IF }X\neq0\text{ GOTO }A\end{array}
\end{equation*}
If the initial value $x$ of $X$ is not 0,  the effect of this program is to copy $x$ into $Y$ and to decrement the value of $X$ down to 0. We will say that this program \textit{computes} the function $$f(x)=\left\{\begin{matrix}1&\quad\text{if}\quad x=0\\x&\quad\text{otherwise.}\end{matrix}\right.$$

Although the preceding program is a perfectly well-defined program of our language $\mathscr{L}$,  we may think of it as having arisen in an attempt to write a program that copies the value of $X$ into $Y$, and therefore containing a "bug" because it does not handle 0 correctly. The following slightly more complicated example remedies this situation.
\begin{equation*}
    \begin{aligned}[A]\quad&\mathrm{IF}\;X\neq0\;\mathrm{GOTO}\;B\\&Z\leftarrow Z+1\\&\mathrm{IF}\;Z\neq0\;\mathrm{GOTO}\;E\\ [B]\quad&X\leftarrow X-1\\&Y\leftarrow Y+1\\&Z\leftarrow Z+1\\&\mathrm{IF}\;Z\neq0\;\mathrm{GOTO}\;A\end{aligned}
\end{equation*}

At first glance $Z$'s role in the computation may not be obvious. It is used simply to allow us to code an \textit{unconditional branch}. That is, the program segment
\begin{equation}
    \begin{aligned}&Z\leftarrow Z+1\\&\text{IF }Z\neq 0\text{ GOTO }L\end{aligned}
    \label{2.1}
\end{equation}
has the effect (ignoring the effect on the value of $Z$) of an instruction
\begin{center}
    GOTO $L$
\end{center}
such as is available in most programming languages. Now GOTO $L$ is not an instruction in our language $\mathscr{L}$, but since we will frequently have use for such an instruction, we can use it as an abbreviation for the program segment (\ref{2.1}). Such an abbreviating pseudoinstruction will be called a \textit{macro} and the program or program segment which it abbreviates will be called it \textit{macro expansion}.

For our final example, we take the program
\begin{equation*}
    \begin{aligned}&Y\leftarrow X_{1}\\ &Z\leftarrow X_{2}\\ [C]\quad&\text{IF }Z\neq0\text{ GOTO }A\\ &\text{GOTO }E\\ [A]\quad&\text{IF }Y\neq0\text{ GOTO }B\\ &\text{GOTO }A\\ [B]\quad&Y\leftarrow Y-1\\ &Z\leftarrow Z-1\\ &\text{GOTO }C\end{aligned}
\end{equation*}

What happens if we begin with a value of $X_1$ less than the value of $X_2$? At this point the computation enters the "loop":
\begin{equation*}
    \begin{aligned}[A]\quad&\text{IF }Y\neq 0\text{ GOTO }B\\&\text{GOTO }A\end{aligned}
\end{equation*}
Since $y=0$, there is no way out of this loop and the computation will continue "forever." Thus, if we begin with $X_1=m$, $X_2=n$, where $m<n$, the computation will never terminate. In this case (and in similar cases) we will say that the program computes the \textit{partial function} $$g(x_1,x_2)=\begin{cases}x_1-x_2&\quad\text{if}\quad x_1\geq x_2\\\uparrow&\quad\text{if}\quad x_1<x_2.\end{cases}$$

\section{Syntax}

The symbols $$X_1\;X_2\;X_3\;\cdots$$ are called \textit{input variables}, $$Z_1\;Z_2\;Z_3\;\cdots$$ are called \textit{local variables}, and $Y$ is called the \textit{output variable} of $\mathscr{L}$. The symbols $$A_1,\;B_1\;C_1\;D_1\;E_1\;A_2\;B_2\;\cdots$$ are called \textit{labels} of $\mathscr{L}$. A \textit{statement} is one of the following:
\begin{equation*}
    \begin{aligned}&V\leftarrow V+1\\&V\leftarrow V-1\\&V\leftarrow V\\&\text{IF }V\neq 0\text{ GOTO }L\end{aligned}
\end{equation*}
where $V$ may be any variable and $L$ may be any label.

Next, an \textit{instruction} is either a statement (in which case it is also called an \textit{unlabeled} instruction) or $[L]$ followed by a statement (in which case the instruction is said to have $L$ as its label or to be labeled $L$). A \textit{program} is a list (i.e., a finite sequence) of instructions. The length of this list is called the \textit{Length} of the progra. It is useful to include the \textit{empty program} of length 0, which of course contains no instructions.

A \textit{state of a program} $\mathscr{P}$ is a list of equations of the form $V=m$, where $V$ is a variable and $m$ is a number, including an equation for each variable that occurs in $\mathscr{P}$ and including no two equations with the same variable. As an example, let $\mathscr{P}$ be the program which contains the variables $X\;Y\;Z$. (The definition of \textit{state} does not require that the state can actually be "attained" from some initial state.) The list $$X=3,\quad Z=3$$ is \textit{not} a state of $\mathscr{P}$ since no equation in $Y$ occurs. Likewise, the list $$X=3,\quad X=4,\quad Y=2,\quad Z=2$$ is \textit{not} a state of $\mathscr{P}$: there are two equations in $X$.

Let $\sigma$ be a state of $\mathscr{P}$ and let $V$ be a variable that occurs in $\sigma$. The \textit{value of} $V$ \textit{at} $\sigma$ is then the (unique) number $q$ such that the equation $V=q$ is one of the equations making up $\sigma$.

Suppose we have a program $\mathscr{P}$ and a state $\sigma$ of $\mathscr{P}$. In order to say what happens "next," we also need to know which instruction of $\mathscr{P}$ is about to be executed. We therefore define a \textit{snapshot} or \textit{instantaneous description} of a program $\mathscr{P}$ of length $n$ to be a pair $(i,\sigma)$ where $1\le i\le n+1$, and $\sigma$ is a state of $\mathscr{P}$.

If $s=(i,\sigma)$ is a snapshot of $\mathscr{P}$ and $V$ is a variable of $\mathscr{P}$, then the \textit{value} of $V$ at $s$ just means the value of $V$ at $\sigma$.

A snapshot $(i,\sigma)$ of a program $\mathscr{P}$ of length $n$ is called \textit{terminal} if $i=n+1$. If $(i,\sigma)$ is a nonterminal snapshot of $\mathscr{P}$, we define the \textit{successor} of $(i,\sigma)$ to be the snapshot $(j,\tau)$ defined as follows:
\begin{itemize}
    \item[\textit{Case} 1.] The $i$th instruction of $\mathscr{P}$ is $V\leftarrow V+1$ and $\sigma$ contains the equation $V=m$. Then $j=i+1$ and $\tau$ is obtained from $\sigma$ by replacing the equation $V=m$ by $V=m+1$ (i.e., the value of $V$ at $\tau$ is $m+1$).
    \item[\textit{Case} 2.] The $i$th instruction of $\mathscr{P}$ is $V\leftarrow V-1$ and $\sigma$ contains the equation $V=m$. Then $j=i+1$ and $\tau$ is obtained from $\sigma$ by replacing the equation $V=m$ by $V=m-1$ if $m\neq 0$; if $m=0$, $\tau=\sigma$.
    \item[\textit{Case} 3.] The $i$th instruction of $\mathscr{P}$ is $V\leftarrow V$. Then $\tau=\sigma$ and $j=i+1$.
    \item[\textit{Case} 4.] The $i$th instruction of $\mathscr{P}$ is IF $V\neq 0$ GOTO $L$. Then $\tau=\sigma$, and there are two subcases:
    \item[\textit{Case} 4a.] $\sigma$ contains the equation $V=0$. Then $j=i+1$.
    \item[\textit{Case} 4b.] $\sigma$ contains the equation $V=m$ where $m\neq 0$. Then, if there is an instruction of $\mathscr{P}$ labeled $L$, $j$ is the \textit{least number} such that the $j$th instruction of $\mathscr{P}$ is labeled $L$. Otherwise, $j=n+1$.
\end{itemize}

A \textit{computation} of a program $\mathscr{P}$ is defined to be a sequence (i.e., a list) $s_1,s_2,\ldots,s_k$ of snapshots of $\mathscr{P}$ such that $s_{i+1}$ is the successor of $s_i$ for $i=1,2,\cdots,k-1$ and $s_k$ is terminal.

Note that we have not forbidden a program to contain more than one instruction having the same label. However, our definition of successor of a snapshot, in effect, interprets a branch instruction as always referring to the \textit{first} statement in the program having the label in question.

\section{Computable Functions}

One would expect a program that computes a function of $m$ variables to contain the input variables $X_1,X_2,\ldots,X_m$, and the output variable $Y$, and to have all other variables (if any) in the program to be local.

Thus, let $\mathscr{P}$ be any program in the language $\mathscr{L}$ and let $r_1,\ldots,r_m$ be $m$ given numbers. We form the state $\sigma$ of $\mathscr{P}$ which consists of the equations $$X_1=r_1,\quad X_2=r_2,\quad \ldots,\quad X_m=r_m,\quad Y=0$$ together with the equations $V=0$ for each variable $V$ in $\mathscr{P}$ other than $X_1,\ldots,X_m,Y$. We will call this the \textit{initial state}, and the snapshot $(1,\sigma)$, the \textit{initial snapshot}.

\begin{itemize}
    \item[\textit{Case} 1.] \textit{There is a computation} $s_1,s_2,\ldots,s_k$ of $\mathscr{P}$ \textit{beginning with the initial snapshot}. Then we write $\psi_{\mathscr{P}}^{(m)}(r_1,\ldots,r_m)$ for the value of the variable $Y$ at the (terminal) snapshot $s_k$.
    \item[\textit{Case} 2.] \textit{There is no such computation}; i.e., there is an \textit{infinite} sequence $s_1,s_2,s_3,\ldots$ beginning with the initial snapshot where each $s_{i+1}$ is the successor of $s_i$. In this case $\psi_{\mathscr{P}}^{(m)}(r_1,\ldots,r_m)$ is undefined.
\end{itemize}

For any program $\mathscr{P}$ and any positive integer $m$, the function $\psi_{\mathscr{P}}^{(m)}(r_1,\ldots,r_m)$ is said to be \textit{computed} by $\mathscr{P}$. A given partial function $g$ (of one or more variables) is said to be \textit{partially computable} if it is computed by some program.

A given function $g$ of $m$ variables is called \textit{total} if $g(r_1,\ldots,r_m)$ is defined for \textit{all} $r_1,\ldots,r_m$. A function is said to be \textit{computable} of it is both partially computable and total.

Partially computable functions are also called \textit{partial recursive}, and computable functions, i.e., functions that are both total and partial recursive, are called \textit{recursive}.

\section{More about Macros}

We now see how to augment our language to include macros of the form
\begin{center}
    IF $P(V_1,\ldots,V_n)$ GOTO $L$
\end{center}
where $P(x_1,\ldots,x_n)$ is a computable predicate. Here we are making use of the convention that $$\text{TRUE}=1,\quad\text{FALSE}=0.$$ Hence predicates are just total functions whose values are always either 0 or 1. And therefore, it makes perfect sense to say that some given \textit{predicate} is or is not computable.

\chapter{Primitive Recursive Functions}
\section{Composition}

We want to combine computable functions in such a way that the output of one becomes an input to another. In the simplest case we combine functions $f$ and $g$ to obtain the function $$h(x)=f(g(x)).$$

More generally, for functions of several variables:

\defn{}{
    Let $f$ be a function of $k$ variables and let $g_1,\ldots,g_k$ be functions of $n$ variables. Let $$h(x_1,\ldots,x_n)=f(g_1(x_1,\ldots,x_n),\ldots,g_k(x_1,\ldots,x_n)).$$ Then $h$ is said to be obtained from $f$ and $g_1,\ldots,g_k$ by \textit{composition}.
}

\thm{}{
    If $h$ is obtained from the (partially) computable functions $f,g_1,\ldots,g_k$ by composition, then $h$ is (partially) computable.

    The word \textit{partially} is placed in parentheses in order to assert the correctness of the statement with the word included or omitted in both places.
}

\section{Recursion}

Suppose $k$ is some fixed number and
\begin{equation}
    \begin{aligned}h(0)&=k,\\h(t+1)&=g(t,h(t)),\end{aligned}
    \label{2.1}
\end{equation}
where $g$ is some given \textit{total} function of two variables. Then $h$ is said to be obtained from $g$ by \textit{primitive recursion}, or simply \textit{recursion}.

\thm{}{
    Let $h$ be obtained from $g$ as in (\ref{2.1}), and let $g$ be computable. Then $h$ is also computable.
}

A slightly more complicated kind of recursion is involved when we have
\begin{equation}
    \begin{aligned}h(x_1,\ldots,x_n,0)&=f(x_1,\ldots,x_n),\\h(x_1,\ldots,x_n,t+1)&=g(t,h(x_1,\ldots,x_n,t),x_1,\ldots,x_n).\end{aligned}
    \label{2.2}
\end{equation}
Here the function $h$ of $n+1$ variables is said to be obtained by \textit{primitive recursion}, or simply \textit{recursion}, from the total functions $f$ (of $n$ variables) and $g$ (of $n+2$ variables). Again we have

\thm{}{
    Let $h$ be obtained from $f$ and $g$ as in (\ref{2.2}) and let $f$, $g$ be computable. Then $h$ is also computable.
}

\section{PRC Classes}

Now we need some functions on which to get started. These will be $$\begin{aligned}s(x)&=x+1,\\n(x)&=0,\end{aligned}$$ and the \textit{projection functions} $$u_i^n(x_1,\ldots,x_n)=x_i,\quad1\le i\le n.$$ The functions $s$, $n$, and $u_i^n$ are called the \textit{initial functions}.

\defn{}{
    A class of total functions $\mathscr{C}$ is called a $\textit{PRC}$ \textit{class} if
    \begin{enumerate}
        \item the initial functions belong to $\mathscr{C}$.
        \item a function obtained from functions belonging to $\mathscr{C}$ by either composition or recursion also belongs to $\mathscr{C}$.
    \end{enumerate}
}

Then we have

\thm{}{
    The class of computable functions is a PRC class.
}

\defn{}{
    A function is called \textit{primitive recursive} if it can be obtained from the initial functions by a finite number of applications of composition and recursion.
}

It is obvious from this definition that

\cor{
    The class of primitive recursive functions is a PRC class.
}

Actually we can say more:

\thm{}{
    A function is primitive recursive if and only if it belongs to every PRC class.
}

\cor{
    Every primitive recursive function is computable.
}

\section{Some Primitive Recursive Functions}

The \textit{predecessor function} $p(x)$ is defined as follows: $$p(x)=\left\{\begin{array}{rll}x-1&\mathrm{if}\quad x\neq0\\0&\mathrm{if}\quad x=0.\end{array}\right.$$

\section{Primitive Recursive Predicates}

\thm{}{
    Let $\mathscr{C}$ be a PRC class. If $P$, $Q$ are predicates that belong to $\mathscr{C}$, then so are $\sim P$, $P\lor Q$, and $P\&Q$.
}

A result which refers to PRC classes can be applied to the two classes we have shown to be PRC. That is, taking $\mathscr{C}$ to be the class of all primitive recursive functions, we have

\cor{
    If $P$, $Q$ are primitive recursive predicates, then so are $\sim P$, $P\lor Q$, and $P\&Q$.
}

Similarly taking $\mathscr{C}$ to be the class of all computable functions, we have

\cor{
    If $P$, $Q$ are computable predicates, then so are $\sim P$, $P\lor Q$, and $P\&Q$.
}

\thm{Definition by Cases}{
    Let $\mathscr{C}$ be a PRC class. Let the function $g$, $h$ and the predicate $P$ belong to $\mathscr{C}$. Let $$f(x_1,\ldots,x_n)=\begin{cases}g(x_1,\ldots,x_n)&\quad\mathrm{if}\quad P(x_1,\ldots,x_n)\\h(x_1,\ldots,x_n)&\quad\mathrm{otherwise}.\end{cases}$$ Then $f$ belongs to $\mathscr{C}$.

    This will be recognized as a version of the familiar "if...then..., else..." statement.

    \label{Theorem:5.4}
}

\cor{
    Let $\mathscr{C}$ be a PRC class, let $n$-ary functions $g_1,\ldots,g_m,h$ and predicates $P_1,\ldots,P_m$ belong to $\mathscr{C}$, and let $$P_i(x_1,\ldots,x_n)\&P_j(x_1,\ldots,x_n)=0$$ for all $1\le i<j\le m$ and all $x_1,\ldots,x_n$. If $$f(x_{1},\ldots,x_{n})=\begin{cases}g_{1}(x_{1},\ldots,x_{n})&\quad\mathrm{if}\quad P_{1}(x_{1},\ldots,x_{n})\\\quad\quad\vdots&\quad\quad\quad\vdots\\g_{m}(x_{1},\ldots,x_{n})&\quad\mathrm{if}\quad P_{m}(x_{1},\ldots,x_{n})\\h(x_{1},\ldots,x_{n})&\quad\mathrm{otherwise},\end{cases}$$ then $f$ also belongs to $\mathscr{C}$.
}

\section{Iterated Operations and Bounded Quantifiers}

\thm{}{
    Let $\mathscr{C}$ be a PRC class. If $f(t,x_1,\ldots,x_n)$ belongs to $\mathscr{C}$, then so do the functions $$g(y,x_1,\ldots,x_n)=\sum\limits_{t=0}^{y}f(t,x_1,\ldots,x_n)$$ and $$h(y,x_1,\ldots,x_n)=\prod\limits_{t=0}^yf(t,x_1,\ldots,x_n).$$

    A common error is to attempt to prove this by using mathematical induction on $y$. A little reflection reveals that such an argument by induction shows that $$g(0,x_1,\ldots,x_n),g(1,x_1,\ldots,x_n),\ldots$$ all belong to $\mathscr{C}$, but not that the function $g(y,x_1,\ldots,x_n)$, one of whose arguments is $y$, belongs to $\mathscr{C}$.

    \label{Theorem:6.1}
}

Sometimes we will want to begin the summation (or product) at 1 instead of 0. Then the initial recursion equations can be taken to be $$g(0,x_1,\ldots,x_n)=0,$$$$h(0,x_1,\ldots,x_n)=1,$$ with the equations for $g(t+1,x_1,\ldots,x_n)$ and $h(t+1,x_1,\ldots,x_n)$. Note that we are implicitly defining a vacuous sum to be 0 and a vacuous product to be 1. With this understanding we have proved

\cor{
    If $f(t,x_1,\ldots,x_n)$ belongs to the PRC class $\mathscr{C}$, then so do the functions $$g(y,x_1,\ldots,x_n)=\sum\limits_{t=1}^yf(t,x_1,\ldots,x_n)$$ and $$h(y,x,\ldots,x_n)=\prod\limits_{t=1}^yf(t,x_1,\ldots,x_n).$$
}

We have

\thm{}{
    If the predicate $P(t,x_1,\ldots,x_n)$ belongs to some PRC class $\mathscr{C}$, then so do the predicates $$(\forall t)_{\leq y}P(t,x_1,\ldots,x_n)\quad\mathrm{~and~}\quad(\exists t)_{\leq y}P(t,x_1,\ldots,x_n).$$

    \label{Theorem:6.3}
}

The predicate "$x$ is a prime" is primitive recursive since $$\text{Prime}(x)\Leftrightarrow x>1\&(\forall t)_{\le x}\{t=1\lor t=x\lor\sim(t|x)\}$$ (A number is a \textit{prime} if it is greater than 1 and it has no divisors other than 1 and itself.)

\section{Minimalization}

Let $P(t,x_1,\ldots,x_n)$ belong to some given PRC class $\mathscr{C}$. Then by Theorem \ref{Theorem:6.1}.1, the function $$g(y,x_1,\ldots,x_n)=\sum_{u=0}^y\prod_{t=0}^u\alpha(P(t,x_1,\ldots,x_n))$$ also belongs to $\mathscr{C}$. Suppose for definiteness that for some value of $t_0\le y$, $$P(t,x_1,\ldots,x_n)=0\quad\text{for }t<t_0$$ but $$P(t_0,x_1,\ldots,x_n)=1,$$ i.e., that $t_0$ \textit{is the least value of} $t\le y$ \textit{for which} $P(t,x_1,\ldots,x_n)$ \textit{is true}. Then $$\prod_{t=0}^u\alpha(P(t,x_1,\ldots,x_n))=\left\{\begin{array}{ll}1&\text{if }u<t_0\\0&\text{if }u\ge t_0.\end{array}\right.$$ Hence, $$g(y,x_1,\ldots,x_n)=\sum_{u<t_0}1=t_0,$$ so that $g(y,x_1,\ldots,x_n)$ is the least value of $t$ for which $P(t,x,\ldots,x_n)$ is true. Now, we define $$\min_{t\le y}P(t,x_1,\ldots,x_n)=\left\{\begin{array}{ll}g(y,x_1,\ldots,x_n)&\text{if }(\exists t)_{\le y}P(t,x_1,\ldots,x_n)\\0&\text{otherwise}.\end{array}\right.$$ Thus, $\min_{t\le y}P(t,x_1,\ldots,x_n)$ \textit{is the least value of} $t\le y$ \textit{for which} $P(t,x_1,\ldots,x_n)$ \textit{is true, if such exists; otherwise it assumes the} (default) \textit{value} 0. Using Theorems \ref{Theorem:5.4}.4 and \ref{Theorem:6.3}.3, we have

\thm{}{
    If $P(t,x_1,\ldots,x_n)$ belongs to some PRC class $\mathscr{C}$ and $f(y,x_1,\ldots,x_n)=\min_{t\le y}P(t,x_1,\ldots,x_n)$, then $f$ also belongs to $\mathscr{C}$.

    The operation "$\min_{t\le y}$" is called \textit{bounded minimalization}.
}

$R(x,y)$ is the \textit{remainder} when $x$ is divided by $y$.

Here, for $n>0$, $p_n$ is the $n$th prime number (in order of size). So that $p_n$ be a total function, we set $p_0=0$.

Consider the recursion equations $$\begin{aligned}p_0&=0,\\p_{n+1}&=\min_{t\le p_n!+1}[\text{Prime}(t)\& t>p_n].\end{aligned}$$ To see that these equations are correct we must verify the inequality
\begin{equation}
    p_{n+1}\le (p_n)!+1.
    \label{eqs.7.1}
\end{equation}

We write $$\min_y P(x_1,\ldots,x_n,y)$$ for the least value of $y$ for which the predicate $P$ is true \textit{if there is one. If there is no value of $y$ for which $P(x_1,\ldots,x_n,y)$ is true, then $\min_yP(x_1,\ldots,x_n,y)$ is undefined}.

% %--------------------------------------------------------------------------
% %         Bibliographie 
% %--------------------------------------------------------------------------
\end{document}
